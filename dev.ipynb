{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "363b3542-2492-408c-b446-9667f95b8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import config\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset as d\n",
    "from importlib import reload\n",
    "import trainer as t\n",
    "import util \n",
    "import loss as l\n",
    "import model as m\n",
    "\n",
    "reload(util)\n",
    "reload(d)\n",
    "reload(t)\n",
    "reload(l)\n",
    "reload(m)\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, batch_size=4, shuffle=True, num_workers=10):\n",
    "    \"\"\"Return PyTorch DataLoader for the given dataset.\"\"\"\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1436aee-0484-4959-ae54-24d9046f2e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /workspace/mydir/obb_anns_hausarbeit/ds2_dense/ds2_dense/gt_space.json\n"
     ]
    }
   ],
   "source": [
    "de = util.DataExtractor()\n",
    "gt_df = de.normalizedData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28315f6-008f-458c-bf1c-b786cc85a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loadMode] No checkpoint found at model_dumps/mythird.pth â€” starting fresh\n",
      "000034 total:3267.2788 l_xy:434.4521 l_wh:177.6105 l_obj:118.7612 l_noobj:340.8746 l_cls:2195.5804\n",
      "000068 total:2266.4539 l_xy:352.0799 l_wh:154.4650 l_obj:68.7563 l_noobj:331.5160 l_cls:1359.6367\n",
      "000102 total:1900.9626 l_xy:324.4780 l_wh:154.9146 l_obj:60.7162 l_noobj:324.3095 l_cls:1036.5444\n",
      "000136 total:1836.0791 l_xy:315.3289 l_wh:152.9963 l_obj:59.8803 l_noobj:317.9997 l_cls:989.8740\n",
      "000170 total:1769.6904 l_xy:319.2455 l_wh:147.3351 l_obj:60.7318 l_noobj:313.7690 l_cls:928.6090\n",
      "000204 total:1396.3098 l_xy:263.7465 l_wh:130.7266 l_obj:44.6954 l_noobj:309.1795 l_cls:647.9618\n",
      "000238 total:1529.2920 l_xy:281.6438 l_wh:139.4140 l_obj:51.4913 l_noobj:306.8749 l_cls:749.8679\n",
      "000272 total:1389.8447 l_xy:263.1534 l_wh:126.2498 l_obj:47.9516 l_noobj:304.4162 l_cls:648.0737\n",
      "000306 total:1423.9808 l_xy:274.2342 l_wh:141.8749 l_obj:51.2642 l_noobj:302.0798 l_cls:654.5276\n",
      "000340 total:1232.1398 l_xy:242.4061 l_wh:119.3675 l_obj:42.2730 l_noobj:299.1280 l_cls:528.9653\n",
      "000341 total:1207.0353 l_xy:247.9180 l_wh:135.1102 l_obj:37.5423 l_noobj:299.9986 l_cls:486.4662\n",
      "Epoch 1 avg total:1799.4608 l_xy:306.9033 l_wh:144.4679 l_obj:60.5844 l_noobj:314.9707 l_cls:972.5345\n",
      "000375 total:1180.3973 l_xy:232.4870 l_wh:121.7224 l_obj:39.9947 l_noobj:296.8769 l_cls:489.3163\n",
      "000409 total:1252.8161 l_xy:254.0294 l_wh:128.6009 l_obj:44.3993 l_noobj:295.8956 l_cls:529.8909\n",
      "000443 total:1393.1414 l_xy:273.3710 l_wh:143.0582 l_obj:52.1508 l_noobj:294.7057 l_cls:629.8557\n",
      "000477 total:1204.2391 l_xy:240.5465 l_wh:130.2786 l_obj:41.2760 l_noobj:293.2514 l_cls:498.8866\n",
      "000511 total:1149.1702 l_xy:232.8089 l_wh:128.7651 l_obj:39.0553 l_noobj:291.0829 l_cls:457.4580\n",
      "000545 total:1206.6205 l_xy:238.0303 l_wh:126.5655 l_obj:40.4098 l_noobj:289.9041 l_cls:511.7107\n",
      "000579 total:1083.5340 l_xy:223.7968 l_wh:122.1862 l_obj:37.1946 l_noobj:289.1836 l_cls:411.1728\n",
      "000613 total:1088.4894 l_xy:226.3984 l_wh:129.7713 l_obj:38.3381 l_noobj:287.4362 l_cls:406.5454\n",
      "000647 total:1087.8297 l_xy:218.3087 l_wh:119.0812 l_obj:36.7271 l_noobj:286.7676 l_cls:426.9449\n",
      "000681 total:1089.7665 l_xy:229.5810 l_wh:123.5600 l_obj:38.0712 l_noobj:286.1079 l_cls:412.4463\n",
      "000682 total:621.5602 l_xy:98.1945 l_wh:60.7470 l_obj:17.2790 l_noobj:283.7592 l_cls:161.5805\n",
      "Epoch 2 avg total:1171.9815 l_xy:236.5289 l_wh:127.1636 l_obj:40.6928 l_noobj:291.0996 l_cls:476.4965\n",
      "000716 total:1011.2899 l_xy:215.7148 l_wh:123.1527 l_obj:36.5627 l_noobj:284.3922 l_cls:351.4674\n",
      "000750 total:1036.0312 l_xy:218.2879 l_wh:128.0098 l_obj:36.0073 l_noobj:284.0201 l_cls:369.7062\n",
      "000784 total:1004.6540 l_xy:211.7603 l_wh:123.7191 l_obj:33.6398 l_noobj:282.7337 l_cls:352.8011\n",
      "000818 total:997.0196 l_xy:202.9535 l_wh:118.7857 l_obj:32.5166 l_noobj:282.0971 l_cls:360.6668\n",
      "000852 total:1033.8307 l_xy:215.5635 l_wh:116.6718 l_obj:35.1814 l_noobj:281.2219 l_cls:385.1921\n",
      "000886 total:1107.8370 l_xy:229.6565 l_wh:130.2277 l_obj:38.8813 l_noobj:281.2835 l_cls:427.7880\n",
      "000920 total:1059.9874 l_xy:229.4348 l_wh:129.8446 l_obj:39.3236 l_noobj:280.4931 l_cls:380.8913\n",
      "000954 total:962.2291 l_xy:199.6211 l_wh:112.3952 l_obj:32.5772 l_noobj:279.6514 l_cls:337.9841\n",
      "000988 total:1055.6201 l_xy:222.3238 l_wh:125.2319 l_obj:37.1190 l_noobj:279.2202 l_cls:391.7252\n",
      "001022 total:917.3674 l_xy:192.6785 l_wh:108.1143 l_obj:30.2734 l_noobj:278.0769 l_cls:308.2244\n",
      "001023 total:531.5569 l_xy:97.6121 l_wh:52.4117 l_obj:6.8469 l_noobj:272.2904 l_cls:102.3958\n",
      "Epoch 3 avg total:1017.1584 l_xy:213.4587 l_wh:121.4123 l_obj:35.1251 l_noobj:281.2925 l_cls:365.8697\n",
      "001057 total:921.8380 l_xy:196.8273 l_wh:117.9864 l_obj:30.6054 l_noobj:277.0700 l_cls:299.3490\n",
      "001091 total:1005.9123 l_xy:222.2695 l_wh:130.7707 l_obj:36.0249 l_noobj:277.5300 l_cls:339.3172\n",
      "001125 total:966.8076 l_xy:208.2890 l_wh:121.9172 l_obj:33.3132 l_noobj:276.5213 l_cls:326.7669\n",
      "001159 total:978.5987 l_xy:210.9574 l_wh:122.0946 l_obj:34.2812 l_noobj:276.3525 l_cls:334.9130\n",
      "001193 total:1015.8214 l_xy:219.2181 l_wh:130.7043 l_obj:34.7396 l_noobj:275.6333 l_cls:355.5262\n",
      "001227 total:833.4613 l_xy:179.5396 l_wh:106.7862 l_obj:26.8629 l_noobj:274.2710 l_cls:246.0016\n",
      "001261 total:889.9643 l_xy:189.7507 l_wh:114.2389 l_obj:28.7797 l_noobj:273.9745 l_cls:283.2204\n",
      "001295 total:906.0620 l_xy:189.9794 l_wh:108.7940 l_obj:29.4720 l_noobj:273.5954 l_cls:304.2211\n",
      "001329 total:867.5274 l_xy:186.5027 l_wh:112.6096 l_obj:27.4063 l_noobj:272.9942 l_cls:268.0146\n",
      "001363 total:891.6161 l_xy:187.5039 l_wh:108.3523 l_obj:29.0937 l_noobj:272.8861 l_cls:293.7802\n",
      "001364 total:693.4091 l_xy:130.2146 l_wh:66.8717 l_obj:13.7849 l_noobj:272.4815 l_cls:210.0564\n",
      "Epoch 4 avg total:927.0737 l_xy:198.8818 l_wh:117.2772 l_obj:31.0072 l_noobj:275.0752 l_cls:304.8323\n",
      "001398 total:886.4715 l_xy:192.4861 l_wh:117.6398 l_obj:30.4135 l_noobj:272.3278 l_cls:273.6042\n",
      "001432 total:881.3791 l_xy:195.4244 l_wh:118.5663 l_obj:30.0953 l_noobj:271.8148 l_cls:265.4782\n",
      "001466 total:864.2942 l_xy:183.7479 l_wh:110.6094 l_obj:27.4068 l_noobj:271.2283 l_cls:271.3017\n",
      "001500 total:875.5737 l_xy:189.4840 l_wh:115.2549 l_obj:29.2585 l_noobj:270.8348 l_cls:270.7414\n",
      "001534 total:859.2686 l_xy:187.0065 l_wh:113.7578 l_obj:28.7942 l_noobj:270.6626 l_cls:259.0475\n",
      "001568 total:843.7077 l_xy:177.8938 l_wh:107.1452 l_obj:27.7152 l_noobj:270.4716 l_cls:260.4819\n",
      "001602 total:937.1665 l_xy:206.0813 l_wh:129.9833 l_obj:33.1290 l_noobj:270.3945 l_cls:297.5784\n",
      "001636 total:828.9209 l_xy:182.6401 l_wh:108.5794 l_obj:26.1361 l_noobj:269.5389 l_cls:242.0264\n",
      "001670 total:837.7743 l_xy:176.9846 l_wh:105.4952 l_obj:25.4817 l_noobj:269.4449 l_cls:260.3679\n",
      "001704 total:844.3665 l_xy:184.4204 l_wh:112.3882 l_obj:27.0464 l_noobj:269.3866 l_cls:251.1249\n",
      "001705 total:763.1850 l_xy:157.2238 l_wh:110.0740 l_obj:25.3229 l_noobj:267.7341 l_cls:202.8302\n",
      "Epoch 5 avg total:865.5911 l_xy:187.5278 l_wh:113.9306 l_obj:28.5382 l_noobj:270.6021 l_cls:264.9924\n",
      "001739 total:788.8762 l_xy:171.7793 l_wh:106.3539 l_obj:25.5000 l_noobj:268.7525 l_cls:216.4906\n",
      "001773 total:885.0847 l_xy:192.3886 l_wh:119.2693 l_obj:29.0310 l_noobj:268.5365 l_cls:275.8593\n",
      "001807 total:838.0025 l_xy:184.6482 l_wh:115.4269 l_obj:28.2033 l_noobj:268.4925 l_cls:241.2316\n",
      "001841 total:798.0197 l_xy:175.2646 l_wh:111.8091 l_obj:26.1799 l_noobj:268.1619 l_cls:216.6042\n",
      "001875 total:882.6442 l_xy:187.2305 l_wh:118.3580 l_obj:27.3650 l_noobj:267.4783 l_cls:282.2125\n",
      "001909 total:820.5684 l_xy:178.8210 l_wh:108.4432 l_obj:24.6399 l_noobj:267.5642 l_cls:241.1000\n",
      "001943 total:823.8992 l_xy:186.8852 l_wh:114.1126 l_obj:27.8451 l_noobj:267.3747 l_cls:227.6815\n",
      "001977 total:814.8107 l_xy:177.2554 l_wh:112.5734 l_obj:24.6696 l_noobj:267.0229 l_cls:233.2895\n",
      "002011 total:747.9561 l_xy:161.9549 l_wh:99.2415 l_obj:21.5004 l_noobj:266.7607 l_cls:198.4987\n",
      "002045 total:759.4203 l_xy:165.1739 l_wh:103.5416 l_obj:22.7912 l_noobj:266.3207 l_cls:201.5929\n",
      "002046 total:540.3363 l_xy:92.3607 l_wh:63.3816 l_obj:11.7438 l_noobj:266.6777 l_cls:106.1725\n",
      "Epoch 6 avg total:815.1200 l_xy:177.8886 l_wh:110.7736 l_obj:25.7314 l_noobj:267.6437 l_cls:233.0828\n",
      "002080 total:765.5138 l_xy:164.9797 l_wh:102.1816 l_obj:24.7090 l_noobj:266.7390 l_cls:206.9046\n",
      "002114 total:815.7733 l_xy:179.7209 l_wh:115.1220 l_obj:25.6562 l_noobj:266.2776 l_cls:228.9967\n",
      "002148 total:831.0779 l_xy:182.3223 l_wh:109.4937 l_obj:26.0347 l_noobj:266.2257 l_cls:247.0015\n",
      "002182 total:779.5176 l_xy:170.6552 l_wh:109.9540 l_obj:24.6676 l_noobj:265.9990 l_cls:208.2418\n",
      "002216 total:746.3951 l_xy:164.6360 l_wh:106.7729 l_obj:22.4358 l_noobj:265.8279 l_cls:186.7224\n",
      "002250 total:817.5808 l_xy:182.0923 l_wh:115.5404 l_obj:25.4250 l_noobj:265.3715 l_cls:229.1516\n",
      "002284 total:732.3417 l_xy:153.8527 l_wh:99.3701 l_obj:20.4320 l_noobj:265.4863 l_cls:193.2007\n",
      "002318 total:754.3540 l_xy:169.5123 l_wh:105.0761 l_obj:23.3670 l_noobj:265.7124 l_cls:190.6862\n",
      "002352 total:751.7424 l_xy:164.2040 l_wh:112.1102 l_obj:22.9697 l_noobj:264.9173 l_cls:187.5412\n"
     ]
    }
   ],
   "source": [
    "model = m.YOLOv2Tiny()\n",
    "modelname = \"mythird\"\n",
    "model = util.loadModel(modelname, model, device='cuda')\n",
    "\n",
    "dataset = d.ObjectDetectionDataset(gt_df, config.img_dir)\n",
    "loader = create_dataloader(dataset, batch_size=4, num_workers=16)\n",
    "loss_fn = l.YOLOv2Loss(l_noobj = 0.005, l_wh = 0.05)\n",
    "trainer = t.Trainer(model, loss_fn, loader, epochs=10, device='cuda')\n",
    "\n",
    "try:\n",
    "    trainer.run()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted. Saving model...\")\n",
    "\n",
    "util.saveModel(modelname, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "262f5623-4f76-4f29-9d5f-56503842a88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loadMode] No checkpoint found at model_dumps/mysecond.pth â€” starting fresh\n",
      "step 00017 total:22514.7173 l_xy:588.5753 l_wh:18168.6985 l_obj:390.8917 l_noobj:344.7171 l_cls:3021.8352\n",
      "step 00034 total:20260.8801 l_xy:496.5784 l_wh:16291.4251 l_obj:328.3343 l_noobj:343.1173 l_cls:2801.4252\n",
      "step 00051 total:20274.2609 l_xy:509.5438 l_wh:16738.7811 l_obj:153.8820 l_noobj:340.1066 l_cls:2531.9474\n",
      "step 00068 total:17099.7525 l_xy:449.5083 l_wh:14319.5522 l_obj:85.4881 l_noobj:336.4035 l_cls:1908.8007\n",
      "step 00085 total:17819.9993 l_xy:472.9496 l_wh:15158.8010 l_obj:86.8106 l_noobj:334.9451 l_cls:1766.4929\n",
      "Training interrupted. Saving model...\n",
      "[saveModel] Saved weights to model_dumps/mysecond.pth (device=cuda:0)\n"
     ]
    }
   ],
   "source": [
    "model = m.YOLOv2Tiny()\n",
    "modelname = \"mysecond\"\n",
    "model = util.loadModel(modelname, model, device='cuda')\n",
    "\n",
    "dataset = d.ObjectDetectionDataset(gt_df, config.img_dir)\n",
    "loader = create_dataloader(dataset, batch_size=4, num_workers=16)\n",
    "loss_fn = l.YOLOv2Loss(l_noobj = 0.005)\n",
    "trainer = t.Trainer(model, loss_fn, loader, epochs=10, device='cuda')\n",
    "\n",
    "try:\n",
    "    trainer.run()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted. Saving model...\")\n",
    "\n",
    "util.saveModel(modelname, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
