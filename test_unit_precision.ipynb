{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a301ad2f",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93cbb375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: c:\\Users\\alexh\\Desktop\\cv2\\obb_anns_hausarbeit\\ds2_dense\\ds2_dense\\gt_space.json\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "from importlib import reload\n",
    "import dataset as d\n",
    "import model as m\n",
    "import loss as l\n",
    "reload(util)\n",
    "reload(l)\n",
    "reload(d)\n",
    "reload(m)\n",
    "\n",
    "de = util.DataExtractor()\n",
    "gt_df = de.croppedData()\n",
    "\n",
    "ds = d.CroppedDummyset(gt_df)\n",
    "myDataset = d.CroppedDataset(gt_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a31d3d",
   "metadata": {},
   "source": [
    "## Test unit_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bd6118d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one ['one:1.000', 'half:0.500', 'inverse_half:0.500', 'vertical_half:0.500', 'quarter:0.250', 'checker:0.500', 'random25:0.256']\n",
      "half ['one:1.000', 'half:1.000', 'inverse_half:0.000', 'vertical_half:0.500', 'quarter:0.500', 'checker:0.500', 'random25:0.260']\n",
      "inverse_half ['one:1.000', 'half:0.000', 'inverse_half:1.000', 'vertical_half:0.500', 'quarter:0.000', 'checker:0.500', 'random25:0.252']\n",
      "vertical_half ['one:1.000', 'half:0.500', 'inverse_half:0.500', 'vertical_half:1.000', 'quarter:0.500', 'checker:0.500', 'random25:0.275']\n",
      "quarter ['one:1.000', 'half:1.000', 'inverse_half:0.000', 'vertical_half:1.000', 'quarter:1.000', 'checker:0.500', 'random25:0.285']\n",
      "checker ['one:1.000', 'half:0.500', 'inverse_half:0.500', 'vertical_half:0.500', 'quarter:0.250', 'checker:1.000', 'random25:0.271']\n",
      "random25 ['one:1.000', 'half:0.507', 'inverse_half:0.493', 'vertical_half:0.537', 'quarter:0.278', 'checker:0.529', 'random25:1.000']\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "\n",
    "ds = dataset.CroppedDummyset(gt_df)\n",
    "\n",
    "choices = [\"one\",\"half\",\"inverse_half\",\"vertical_half\",\"quarter\",\"checker\",\"random25\"]\n",
    "def sweep(ds):\n",
    "    res = {}\n",
    "    for p in choices:\n",
    "        P = ds.dummyTensor(p)\n",
    "        row = {}\n",
    "        for t in choices:\n",
    "            T = ds.dummyTensor(t)\n",
    "            iou = eval.pred_to_iou(P, T)\n",
    "            row[t] = eval.unit_precision(P, T, iou)\n",
    "        res[p] = row\n",
    "    return res\n",
    "\n",
    "mat = sweep(ds)\n",
    "for p,row in mat.items():\n",
    "    print(p, [\"%s:%.3f\"%(t,v) for t,v in row.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4975cdaa",
   "metadata": {},
   "source": [
    "# Debug Precision Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616cc8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE: c:\\Users\\alexh\\Desktop\\cv2\\obb_anns_hausarbeit\\eval.py\n",
      "max |bp-bt|: 0.0\n",
      "IoU diag mean/min/max: 1.0 1.0 1.0\n",
      "oh, ho, oo = 0.5 1.0 1.0\n",
      "conf≥thr: 3200 pc==tc: 3200 tp_m: 3200 iou>0: 3200\n",
      "conf≥thr: 1600 pc==tc: 3200 tp_m: 1600 iou>0: 3200\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib\n",
    "\n",
    "# 1) Verify which file you're importing\n",
    "import eval\n",
    "print(\"FILE:\", eval.__file__)\n",
    "\n",
    "# 2) Hard-reload\n",
    "sys.modules.pop('eval', None)\n",
    "eval = importlib.import_module('eval')\n",
    "\n",
    "# 3) Make sure runTests calls debug\n",
    "eval.debug_pred_to_iou()   # should print stuff\n",
    "eval.runTests(gt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453d5ee",
   "metadata": {},
   "source": [
    "# Random Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d05d2652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: Precision = 0.000\n",
      "Sample 1: Precision = 0.000\n",
      "Sample 2: Precision = 0.000\n",
      "Sample 3: Precision = 0.000\n",
      "Sample 4: Precision = 0.000\n",
      "Sample 5: Precision = 0.000\n",
      "Sample 6: Precision = 0.000\n",
      "Sample 7: Precision = 0.000\n",
      "Sample 8: Precision = 0.000\n",
      "Sample 9: Precision = 0.000\n",
      "Average precision over 10 samples: 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import model as m\n",
    "import dataset as d\n",
    "import eval\n",
    "import config as c\n",
    "from importlib import reload\n",
    "reload(eval)\n",
    "reload(d)\n",
    "reload(m)\n",
    "\n",
    "# Assuming gt_df is defined from previous context\n",
    "ds = d.CroppedDataset(gt_df)  # Use the real dataset\n",
    "\n",
    "ds2 = d.CroppedDummyset(gt_df)\n",
    "one = ds2.dummyTensor(\"one\")\n",
    "half = ds2.dummyTensor(\"half\")\n",
    "\n",
    "class FixedYOLOResNet(m.YOLOResNet):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet18(weights=None)\n",
    "        # Adapt for grayscale input\n",
    "        backbone.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=3, padding=3, bias=False)\n",
    "\n",
    "        # Set strides to 1 only for layer2 and layer3 to achieve total downsampling factor of 12 (3*2*2=12)\n",
    "        for layer in [backbone.layer2, backbone.layer3]:\n",
    "            for block in layer:\n",
    "                if hasattr(block, 'conv1'):\n",
    "                    block.conv1.stride = (1, 1)\n",
    "                if hasattr(block, 'downsample') and block.downsample is not None:\n",
    "                    block.downsample[0].stride = (1, 1)\n",
    "\n",
    "        # Backbone up to the feature map (layer4 keeps default stride=2)\n",
    "        self.backbone = torch.nn.Sequential(\n",
    "            backbone.conv1,\n",
    "            backbone.bn1,\n",
    "            backbone.relu,\n",
    "            backbone.maxpool,\n",
    "            backbone.layer1,\n",
    "            backbone.layer2,\n",
    "            backbone.layer3,\n",
    "            backbone.layer4\n",
    "        )\n",
    "\n",
    "        # YOLO detection head\n",
    "        num_features = 512\n",
    "        self.head = torch.nn.Conv2d(num_features, self.A * (5 + self.C), kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "m1 = m.YOLOResNet()#FixedYOLOResNet()\n",
    "m1.eval()  # Ensure evaluation mode\n",
    "\n",
    "precisions = []\n",
    "for i in range(10):\n",
    "    image, target = ds[i]\n",
    "    # Image is [H, W], add channel\n",
    "    image = image.unsqueeze(0)  # [1, H, W]\n",
    "    with torch.no_grad():\n",
    "        pred = m1(image.unsqueeze(0))  # [1, 1, H, W] -> model -> [1, N, N, A, 5+C]\n",
    "        pred = pred.squeeze(0)  # [N, N, A, 5+C]\n",
    "    iou = eval.pred_to_iou(pred, target)\n",
    "    prec = eval.unit_precision(pred, target, iou)\n",
    "    # iou = eval.pred_to_iou(one, half)\n",
    "    # prec = eval.unit_precision(one, half, iou)\n",
    "    precisions.append(prec)\n",
    "    print(f\"Sample {i}: Precision = {prec:.3f}\")\n",
    "\n",
    "average_precision = sum(precisions) / len(precisions) if precisions else 0\n",
    "print(f\"Average precision over 10 samples: {average_precision:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
