{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2772e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import crop, resize, rgb_to_grayscale\n",
    "from torch.utils.data import IterableDataset\n",
    "import itertools\n",
    "from obb_anns import OBBAnns\n",
    "from pathlib import Path\n",
    "import json\n",
    "filepath = r\"C:\\Users\\alexh\\Desktop\\ComputerVision\\Hausarbeit\\deepscores_v2_dense\\ds2_dense\\deepscores_train.json\"\n",
    "basePath = r\"C:\\Users\\alexh\\Desktop\\ComputerVision\\Hausarbeit\\deepscores_v2_dense\\ds2_dense\\images\\\\\" \n",
    "\n",
    "\n",
    "def to_grayscale(tensor):\n",
    "    # tensor: [C, H, W] mit C=3 → gibt [1, H, W] zurück\n",
    "    return rgb_to_grayscale(tensor, num_output_channels=1)\n",
    "\n",
    "class SymbolCropStreamer(IterableDataset):\n",
    "    def __init__(self,target_size=(64, 64), transform=None):\n",
    "        self.data = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "            \n",
    "        self.o = OBBAnns(filepath)\n",
    "        self.o.load_annotations()\n",
    "        self.img_index = 0\n",
    "        self.ann_index = 0\n",
    "        self.img , self.current_anns = self.o.get_img_ann_pair([0])\n",
    "        self.current_src_img = None\n",
    "        self.load_first()\n",
    "        self.target_size = target_size\n",
    "        self.transform = transform\n",
    "\n",
    "    def load_first(self):\n",
    "        self.img, self.current_anns = self.o.get_img_ann_pair([self.img_index])\n",
    "        img_path = Path(basePath) / self.img[0][\"filename\"]\n",
    "        self.current_src_img = read_image(img_path).float() / 255\n",
    "\n",
    "    def load_next(self):\n",
    "        self.img_index += 1\n",
    "        if self.img_index >= len(self.o):\n",
    "            return False\n",
    "        self.ann_index = 0\n",
    "        self.img, self.current_anns = self.o.get_img_ann_pair([self.img_index])\n",
    "        img_path = Path(basePath) / self.img[0][\"filename\"]\n",
    "        self.current_src_img = read_image(img_path).float() / 255\n",
    "        return True\n",
    "    \n",
    "    def get_bounding_box_cat(self):\n",
    "        bb, cat = self.current_anns[0][\"a_bbox\"].values[self.ann_index], self.current_anns[0][\"cat_id\"].values[self.ann_index]\n",
    "        if cat[0] == 135:\n",
    "            print(\"staff line\")\n",
    "            self.ann_index +=1\n",
    "            if self.ann_index >= len(self.current_anns[0]):\n",
    "                r = self.load_next()\n",
    "                if not r:\n",
    "                    return False\n",
    "            return self.get_bounding_box_cat()\n",
    "        return bb, cat[0]\n",
    "        \n",
    "\n",
    "    def __iter__(self):\n",
    "        while self.img_index < len(self.o):\n",
    "            if self.ann_index >= len(self.current_anns[0]):\n",
    "                r = self.load_next()\n",
    "                if not r:\n",
    "                    break\n",
    "            bounding_box, cat = self.get_bounding_box_cat()#Rekursion einführen\n",
    "            x, y, x1, y1 = map(int, bounding_box)\n",
    "            patch = crop(self.current_src_img, top=y, left=x, height=y1 - y, width=x1 - x)\n",
    "            patch = resize(patch, self.target_size)\n",
    "            if self.transform:\n",
    "                patch = self.transform(patch)\n",
    "            self.ann_index += 1\n",
    "            yield patch, cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393e85e",
   "metadata": {},
   "source": [
    "Todo\n",
    " - categories.json besser nachvollziehen. Wie würde der Datensatz aussehen, wenn wir nur mit deepscores arbeiten würden?\n",
    " - Model Trainer implementieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "285655cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_img(patch, cat):\n",
    "    print(f\"Patch shape:\", patch.shape)  # z.B. torch.Size([1, 28, 28])\n",
    "\n",
    "    if patch.dim() == 3 and patch.shape[0] == 1:\n",
    "        # [1, H, W] → [H, W]\n",
    "        img = patch.squeeze(0).cpu().numpy()\n",
    "        cmap = 'gray'\n",
    "    elif patch.dim() == 3 and patch.shape[0] == 3:\n",
    "        # [3, H, W] → [H, W, 3]\n",
    "        img = patch.permute(1, 2, 0).cpu().numpy()\n",
    "        cmap = None\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unerwartete Tensor‐Shape: {patch.shape}\")\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(f\"Category {cat}\", fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "efb8fc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ann_info...\n",
      "done! t=17.85s\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "# dataloader = SymbolCropStreamer()\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def createDataloader():\n",
    "    dataset = SymbolCropStreamer(target_size=(64, 64), transform=to_grayscale)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=32,        # z.B. 32 Patches pro Batch\n",
    "        num_workers=0,        # Anzahl Worker‐Prozesse (je nach CPU-Kernen anpassen)\n",
    "        pin_memory=True       # bei GPU-Training oft sinnvoll\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "dataloader = createDataloader()\n",
    "\n",
    "print(type(dataloader))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "416f239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n",
      "staff line\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for n, (batch_patches, batch_cats) in  enumerate(dataloader):\n",
    "    l.append(batch_cats.tolist())\n",
    "    if(n >= 100):\n",
    "        \n",
    "        break\n",
    "    \n",
    "    for i in range(len(batch_cats)):\n",
    "       # print(batch_cats)\n",
    "       pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b93a3f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    }
   ],
   "source": [
    "flat = [elem for sub in l for elem in sub]\n",
    "len(flat)\n",
    "print(max(flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "592ac761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc6fd8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ann_info...\n",
      "done! t=7.76s\n"
     ]
    }
   ],
   "source": [
    "filepath = r\"C:\\Users\\alexh\\Desktop\\ComputerVision\\Hausarbeit\\deepscores_v2_dense\\ds2_dense\\deepscores_train.json\"\n",
    "basePath = r\"C:\\Users\\alexh\\Desktop\\ComputerVision\\Hausarbeit\\deepscores_v2_dense\\ds2_dense\\images\\\\\" \n",
    "o = OBBAnns(filepath)\n",
    "o.load_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d36c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"categories_sorted.json\", orient=\"index\", indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c54f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "class MyLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLeNet, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels=8, kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels=16, kernel_size = 5, stride = 1, padding = 0) \n",
    "        self.linear1 = nn.Linear(in_features = 2704, out_features = 120)\n",
    "        self.linear2 = nn.Linear(in_features = 120, out_features = 84)\n",
    "        self.linear3 = nn.Linear(in_features = 84, out_features = 136)\n",
    "\n",
    "    def forward(self, x):  \n",
    "        #32x64x64x1\n",
    "        x = self.relu(self.conv1(x)) \n",
    "        #32x60x60x8\n",
    "        x = self.pool(x) \n",
    "        #32x30x30x8\n",
    "        x = self.relu(self.conv2(x)) \n",
    "        #32x26x26x16\n",
    "        x = self.pool(x)\n",
    "        #32x13x13x16\n",
    "        x = self.relu(self.linear1(x.reshape(x.shape[0], -1)))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
