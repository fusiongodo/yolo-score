{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcbafdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 896, 896]           2,352\n",
      "       BatchNorm2d-2         [-1, 16, 896, 896]              32\n",
      "         LeakyReLU-3         [-1, 16, 896, 896]               0\n",
      "        _ConvBlock-4         [-1, 16, 896, 896]               0\n",
      "         MaxPool2d-5         [-1, 16, 448, 448]               0\n",
      "            Conv2d-6         [-1, 32, 448, 448]           4,608\n",
      "       BatchNorm2d-7         [-1, 32, 448, 448]              64\n",
      "         LeakyReLU-8         [-1, 32, 448, 448]               0\n",
      "        _ConvBlock-9         [-1, 32, 448, 448]               0\n",
      "        MaxPool2d-10         [-1, 32, 224, 224]               0\n",
      "           Conv2d-11         [-1, 48, 224, 224]           1,536\n",
      "      BatchNorm2d-12         [-1, 48, 224, 224]              96\n",
      "        LeakyReLU-13         [-1, 48, 224, 224]               0\n",
      "       _ConvBlock-14         [-1, 48, 224, 224]               0\n",
      "           Conv2d-15         [-1, 64, 224, 224]          27,648\n",
      "      BatchNorm2d-16         [-1, 64, 224, 224]             128\n",
      "        LeakyReLU-17         [-1, 64, 224, 224]               0\n",
      "       _ConvBlock-18         [-1, 64, 224, 224]               0\n",
      "           Conv2d-19        [-1, 128, 224, 224]           8,192\n",
      "      BatchNorm2d-20        [-1, 128, 224, 224]             256\n",
      "        LeakyReLU-21        [-1, 128, 224, 224]               0\n",
      "       _ConvBlock-22        [-1, 128, 224, 224]               0\n",
      "        MaxPool2d-23        [-1, 128, 112, 112]               0\n",
      "           Conv2d-24        [-1, 256, 112, 112]         294,912\n",
      "      BatchNorm2d-25        [-1, 256, 112, 112]             512\n",
      "        LeakyReLU-26        [-1, 256, 112, 112]               0\n",
      "       _ConvBlock-27        [-1, 256, 112, 112]               0\n",
      "           Conv2d-28        [-1, 512, 112, 112]       1,179,648\n",
      "      BatchNorm2d-29        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-30        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-31        [-1, 512, 112, 112]               0\n",
      "           Conv2d-32        [-1, 256, 112, 112]         131,072\n",
      "      BatchNorm2d-33        [-1, 256, 112, 112]             512\n",
      "        LeakyReLU-34        [-1, 256, 112, 112]               0\n",
      "       _ConvBlock-35        [-1, 256, 112, 112]               0\n",
      "           Conv2d-36        [-1, 512, 112, 112]       1,179,648\n",
      "      BatchNorm2d-37        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-38        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-39        [-1, 512, 112, 112]               0\n",
      "           Conv2d-40        [-1, 256, 112, 112]         131,072\n",
      "      BatchNorm2d-41        [-1, 256, 112, 112]             512\n",
      "        LeakyReLU-42        [-1, 256, 112, 112]               0\n",
      "       _ConvBlock-43        [-1, 256, 112, 112]               0\n",
      "           Conv2d-44        [-1, 512, 112, 112]       1,179,648\n",
      "      BatchNorm2d-45        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-46        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-47        [-1, 512, 112, 112]               0\n",
      "           Conv2d-48        [-1, 256, 112, 112]         131,072\n",
      "      BatchNorm2d-49        [-1, 256, 112, 112]             512\n",
      "        LeakyReLU-50        [-1, 256, 112, 112]               0\n",
      "       _ConvBlock-51        [-1, 256, 112, 112]               0\n",
      "           Conv2d-52        [-1, 512, 112, 112]       1,179,648\n",
      "      BatchNorm2d-53        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-54        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-55        [-1, 512, 112, 112]               0\n",
      "           Conv2d-56        [-1, 256, 112, 112]         131,072\n",
      "      BatchNorm2d-57        [-1, 256, 112, 112]             512\n",
      "        LeakyReLU-58        [-1, 256, 112, 112]               0\n",
      "       _ConvBlock-59        [-1, 256, 112, 112]               0\n",
      "           Conv2d-60        [-1, 512, 112, 112]       1,179,648\n",
      "      BatchNorm2d-61        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-62        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-63        [-1, 512, 112, 112]               0\n",
      "           Conv2d-64        [-1, 512, 112, 112]         262,144\n",
      "      BatchNorm2d-65        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-66        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-67        [-1, 512, 112, 112]               0\n",
      "           Conv2d-68       [-1, 1024, 112, 112]       4,718,592\n",
      "      BatchNorm2d-69       [-1, 1024, 112, 112]           2,048\n",
      "        LeakyReLU-70       [-1, 1024, 112, 112]               0\n",
      "       _ConvBlock-71       [-1, 1024, 112, 112]               0\n",
      "           Conv2d-72       [-1, 1024, 112, 112]       9,437,184\n",
      "      BatchNorm2d-73       [-1, 1024, 112, 112]           2,048\n",
      "        LeakyReLU-74       [-1, 1024, 112, 112]               0\n",
      "       _ConvBlock-75       [-1, 1024, 112, 112]               0\n",
      "           Conv2d-76        [-1, 846, 112, 112]         866,304\n",
      "      BatchNorm2d-77        [-1, 846, 112, 112]           1,692\n",
      "        LeakyReLU-78        [-1, 846, 112, 112]               0\n",
      "       _ConvBlock-79        [-1, 846, 112, 112]               0\n",
      "================================================================\n",
      "Total params: 22,061,068\n",
      "Trainable params: 22,061,068\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 9.19\n",
      "Forward/backward pass size (MB): 3778.36\n",
      "Params size (MB): 84.16\n",
      "Estimated Total Size (MB): 3871.70\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import model as m\n",
    "\n",
    "model = m.YOLOv2Heavy().cpu()    # move to CPU\n",
    "summary(model, (3, 896, 896), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cade57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv2Heavy(\n",
      "  22.06 M, 100.000% Params, 281.07 GMac, 99.991% MACs, \n",
      "  (model): Sequential(\n",
      "    22.06 M, 100.000% Params, 281.07 GMac, 99.991% MACs, \n",
      "    (0): _ConvBlock(\n",
      "      2.38 k, 0.011% Params, 1.93 GMac, 0.685% MACs, \n",
      "      (conv): Conv2d(2.35 k, 0.011% Params, 1.89 GMac, 0.672% MACs, 3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (bn): BatchNorm2d(32, 0.000% Params, 25.69 MMac, 0.009% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): LeakyReLU(0, 0.000% Params, 12.85 MMac, 0.005% MACs, negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): MaxPool2d(0, 0.000% Params, 12.85 MMac, 0.005% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): _ConvBlock(\n",
      "      4.67 k, 0.021% Params, 944.11 MMac, 0.336% MACs, \n",
      "      (conv): Conv2d(4.61 k, 0.021% Params, 924.84 MMac, 0.329% MACs, 16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, 0.000% Params, 12.85 MMac, 0.005% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): LeakyReLU(0, 0.000% Params, 6.42 MMac, 0.002% MACs, negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (3): MaxPool2d(0, 0.000% Params, 6.42 MMac, 0.002% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): _ConvBlock(\n",
      "      1.63 k, 0.007% Params, 84.3 MMac, 0.030% MACs, \n",
      "      (conv): Conv2d(1.54 k, 0.007% Params, 77.07 MMac, 0.027% MACs, 32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, 0.000% Params, 4.82 MMac, 0.002% MACs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): LeakyReLU(0, 0.000% Params, 2.41 MMac, 0.001% MACs, negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (5): _ConvBlock(\n",
      "      27.78 k, 0.126% Params, 1.4 GMac, 0.497% MACs, \n",
      "      (conv): Conv2d(27.65 k, 0.125% Params, 1.39 GMac, 0.494% MACs, 48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, 0.001% Params, 6.42 MMac, 0.002% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): LeakyReLU(0, 0.000% Params, 3.21 MMac, 0.001% MACs, negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (6): _ConvBlock(\n",
      "      8.45 k, 0.038% Params, 430.31 MMac, 0.153% MACs, \n",
      "      (conv): Conv2d(8.19 k, 0.037% Params, 411.04 MMac, 0.146% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, 0.001% Params, 12.85 MMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): LeakyReLU(0, 0.000% Params, 6.42 MMac, 0.002% MACs, negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (7): MaxPool2d(0, 0.000% Params, 6.42 MMac, 0.002% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): _ConvBlock(\n",
      "      295.42 k, 1.339% Params, 3.71 GMac, 1.319% MACs, \n",
      "      (conv): Conv2d(294.91 k, 1.337% Params, 3.7 GMac, 1.316% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, 0.002% Params, 6.42 MMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): LeakyReLU(0, 0.000% Params, 3.21 MMac, 0.001% MACs, negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (9): _ConvBlock(\n",
      "      1.18 M, 5.352% Params, 14.82 GMac, 5.271% MACs, \n",
      "      (conv): Conv2d(1.18 M, 5.347% Params, 14.8 GMac, 5.264% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(1.02 k, 0.005% Params, 12.85 MMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): LeakyReLU(0, 0.000% Params, 6.42 MMac, 0.002% MACs, negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      1.31 M, 5.948% Params, 16.47 GMac, 5.859% MACs, \n",
      "      (0): _ConvBlock(\n",
      "        131.58 k, 0.596% Params, 1.65 GMac, 0.588% MACs, \n",
      "        (conv): Conv2d(131.07 k, 0.594% Params, 1.64 GMac, 0.585% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, 0.002% Params, 6.42 MMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): LeakyReLU(0, 0.000% Params, 3.21 MMac, 0.001% MACs, negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): _ConvBlock(\n",
      "        1.18 M, 5.352% Params, 14.82 GMac, 5.271% MACs, \n",
      "        (conv): Conv2d(1.18 M, 5.347% Params, 14.8 GMac, 5.264% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1.02 k, 0.005% Params, 12.85 MMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): LeakyReLU(0, 0.000% Params, 6.42 MMac, 0.002% MACs, negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (11): Sequential(\n",
      "      1.31 M, 5.948% Params, 16.47 GMac, 5.859% MACs, \n",
      "      (0): _ConvBlock(\n",
      "        131.58 k, 0.596% Params, 1.65 GMac, 0.588% MACs, \n",
      "        (conv): Conv2d(131.07 k, 0.594% Params, 1.64 GMac, 0.585% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, 0.002% Params, 6.42 MMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): LeakyReLU(0, 0.000% Params, 3.21 MMac, 0.001% MACs, negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): _ConvBlock(\n",
      "        1.18 M, 5.352% Params, 14.82 GMac, 5.271% MACs, \n",
      "        (conv): Conv2d(1.18 M, 5.347% Params, 14.8 GMac, 5.264% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1.02 k, 0.005% Params, 12.85 MMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): LeakyReLU(0, 0.000% Params, 6.42 MMac, 0.002% MACs, negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (12): Sequential(\n",
      "      1.31 M, 5.948% Params, 16.47 GMac, 5.859% MACs, \n",
      "      (0): _ConvBlock(\n",
      "        131.58 k, 0.596% Params, 1.65 GMac, 0.588% MACs, \n",
      "        (conv): Conv2d(131.07 k, 0.594% Params, 1.64 GMac, 0.585% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, 0.002% Params, 6.42 MMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): LeakyReLU(0, 0.000% Params, 3.21 MMac, 0.001% MACs, negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): _ConvBlock(\n",
      "        1.18 M, 5.352% Params, 14.82 GMac, 5.271% MACs, \n",
      "        (conv): Conv2d(1.18 M, 5.347% Params, 14.8 GMac, 5.264% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1.02 k, 0.005% Params, 12.85 MMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): LeakyReLU(0, 0.000% Params, 6.42 MMac, 0.002% MACs, negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (13): Sequential(\n",
      "      1.31 M, 5.948% Params, 16.47 GMac, 5.859% MACs, \n",
      "      (0): _ConvBlock(\n",
      "        131.58 k, 0.596% Params, 1.65 GMac, 0.588% MACs, \n",
      "        (conv): Conv2d(131.07 k, 0.594% Params, 1.64 GMac, 0.585% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, 0.002% Params, 6.42 MMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): LeakyReLU(0, 0.000% Params, 3.21 MMac, 0.001% MACs, negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): _ConvBlock(\n",
      "        1.18 M, 5.352% Params, 14.82 GMac, 5.271% MACs, \n",
      "        (conv): Conv2d(1.18 M, 5.347% Params, 14.8 GMac, 5.264% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1.02 k, 0.005% Params, 12.85 MMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): LeakyReLU(0, 0.000% Params, 6.42 MMac, 0.002% MACs, negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (14): _ConvBlock(\n",
      "      263.17 k, 1.193% Params, 3.31 GMac, 1.177% MACs, \n",
      "      (conv): Conv2d(262.14 k, 1.188% Params, 3.29 GMac, 1.170% MACs, 512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(1.02 k, 0.005% Params, 12.85 MMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): LeakyReLU(0, 0.000% Params, 6.42 MMac, 0.002% MACs, negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (15): _ConvBlock(\n",
      "      4.72 M, 21.398% Params, 59.23 GMac, 21.071% MACs, \n",
      "      (conv): Conv2d(4.72 M, 21.389% Params, 59.19 GMac, 21.057% MACs, 512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(2.05 k, 0.009% Params, 25.69 MMac, 0.009% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): LeakyReLU(0, 0.000% Params, 12.85 MMac, 0.005% MACs, negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (16): _ConvBlock(\n",
      "      9.44 M, 42.787% Params, 118.42 GMac, 42.128% MACs, \n",
      "      (conv): Conv2d(9.44 M, 42.778% Params, 118.38 GMac, 42.114% MACs, 1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(2.05 k, 0.009% Params, 25.69 MMac, 0.009% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): LeakyReLU(0, 0.000% Params, 12.85 MMac, 0.005% MACs, negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (17): _ConvBlock(\n",
      "      868.0 k, 3.935% Params, 10.9 GMac, 3.877% MACs, \n",
      "      (conv): Conv2d(866.3 k, 3.927% Params, 10.87 GMac, 3.866% MACs, 1024, 846, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(1.69 k, 0.008% Params, 21.22 MMac, 0.008% MACs, 846, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): LeakyReLU(0, 0.000% Params, 10.61 MMac, 0.004% MACs, negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total MACs  : 22.06 M\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# pip install ptflops\n",
    "from ptflops import get_model_complexity_info\n",
    "import torch\n",
    "import model as m\n",
    "\n",
    "model = m.YOLOv2Heavy().cuda()  # or .cpu()\n",
    "with torch.cuda.device(0):      # remove if running on CPU\n",
    "    macs, params = get_model_complexity_info(\n",
    "        model,\n",
    "        (3, 896, 896),\n",
    "        as_strings=True,\n",
    "        print_per_layer_stat=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "print(f\"Total MACs  : {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92cfd9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 896, 896]           1,176\n",
      "       BatchNorm2d-2          [-1, 8, 896, 896]              16\n",
      "         LeakyReLU-3          [-1, 8, 896, 896]               0\n",
      "        _ConvBlock-4          [-1, 8, 896, 896]               0\n",
      "         MaxPool2d-5          [-1, 8, 448, 448]               0\n",
      "            Conv2d-6         [-1, 16, 448, 448]           1,152\n",
      "       BatchNorm2d-7         [-1, 16, 448, 448]              32\n",
      "         LeakyReLU-8         [-1, 16, 448, 448]               0\n",
      "        _ConvBlock-9         [-1, 16, 448, 448]               0\n",
      "        MaxPool2d-10         [-1, 16, 224, 224]               0\n",
      "           Conv2d-11         [-1, 24, 224, 224]             384\n",
      "      BatchNorm2d-12         [-1, 24, 224, 224]              48\n",
      "        LeakyReLU-13         [-1, 24, 224, 224]               0\n",
      "       _ConvBlock-14         [-1, 24, 224, 224]               0\n",
      "           Conv2d-15         [-1, 48, 224, 224]          10,368\n",
      "      BatchNorm2d-16         [-1, 48, 224, 224]              96\n",
      "        LeakyReLU-17         [-1, 48, 224, 224]               0\n",
      "       _ConvBlock-18         [-1, 48, 224, 224]               0\n",
      "           Conv2d-19         [-1, 48, 224, 224]           2,304\n",
      "      BatchNorm2d-20         [-1, 48, 224, 224]              96\n",
      "        LeakyReLU-21         [-1, 48, 224, 224]               0\n",
      "       _ConvBlock-22         [-1, 48, 224, 224]               0\n",
      "           Conv2d-23         [-1, 96, 224, 224]          41,472\n",
      "      BatchNorm2d-24         [-1, 96, 224, 224]             192\n",
      "        LeakyReLU-25         [-1, 96, 224, 224]               0\n",
      "       _ConvBlock-26         [-1, 96, 224, 224]               0\n",
      "        MaxPool2d-27         [-1, 96, 112, 112]               0\n",
      "           Conv2d-28         [-1, 48, 112, 112]           4,608\n",
      "      BatchNorm2d-29         [-1, 48, 112, 112]              96\n",
      "        LeakyReLU-30         [-1, 48, 112, 112]               0\n",
      "       _ConvBlock-31         [-1, 48, 112, 112]               0\n",
      "           Conv2d-32         [-1, 96, 112, 112]          41,472\n",
      "      BatchNorm2d-33         [-1, 96, 112, 112]             192\n",
      "        LeakyReLU-34         [-1, 96, 112, 112]               0\n",
      "       _ConvBlock-35         [-1, 96, 112, 112]               0\n",
      "           Conv2d-36         [-1, 96, 112, 112]           9,216\n",
      "      BatchNorm2d-37         [-1, 96, 112, 112]             192\n",
      "        LeakyReLU-38         [-1, 96, 112, 112]               0\n",
      "       _ConvBlock-39         [-1, 96, 112, 112]               0\n",
      "           Conv2d-40        [-1, 128, 112, 112]         110,592\n",
      "      BatchNorm2d-41        [-1, 128, 112, 112]             256\n",
      "        LeakyReLU-42        [-1, 128, 112, 112]               0\n",
      "       _ConvBlock-43        [-1, 128, 112, 112]               0\n",
      "           Conv2d-44        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-45        [-1, 128, 112, 112]             256\n",
      "        LeakyReLU-46        [-1, 128, 112, 112]               0\n",
      "       _ConvBlock-47        [-1, 128, 112, 112]               0\n",
      "           Conv2d-48        [-1, 846, 112, 112]         108,288\n",
      "      BatchNorm2d-49        [-1, 846, 112, 112]           1,692\n",
      "        LeakyReLU-50        [-1, 846, 112, 112]               0\n",
      "       _ConvBlock-51        [-1, 846, 112, 112]               0\n",
      "================================================================\n",
      "Total params: 481,652\n",
      "Trainable params: 481,652\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 9.19\n",
      "Forward/backward pass size (MB): 1166.05\n",
      "Params size (MB): 1.84\n",
      "Estimated Total Size (MB): 1177.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import model as m\n",
    "\n",
    "model = m.YOLOv2Tiny().cpu()    # move to CPU\n",
    "summary(model, (3, 896, 896), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f83a1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [1, 1000]                 --\n",
       "├─Conv2d: 1-1                            [1, 64, 120, 120]         9,408\n",
       "├─BatchNorm2d: 1-2                       [1, 64, 120, 120]         128\n",
       "├─ReLU: 1-3                              [1, 64, 120, 120]         --\n",
       "├─MaxPool2d: 1-4                         [1, 64, 60, 60]           --\n",
       "├─Sequential: 1-5                        [1, 64, 60, 60]           --\n",
       "│    └─BasicBlock: 2-1                   [1, 64, 60, 60]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 60, 60]           36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 60, 60]           128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 60, 60]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 60, 60]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 60, 60]           128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 60, 60]           --\n",
       "│    └─BasicBlock: 2-2                   [1, 64, 60, 60]           --\n",
       "│    │    └─Conv2d: 3-7                  [1, 64, 60, 60]           36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 64, 60, 60]           128\n",
       "│    │    └─ReLU: 3-9                    [1, 64, 60, 60]           --\n",
       "│    │    └─Conv2d: 3-10                 [1, 64, 60, 60]           36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [1, 64, 60, 60]           128\n",
       "│    │    └─ReLU: 3-12                   [1, 64, 60, 60]           --\n",
       "├─Sequential: 1-6                        [1, 128, 30, 30]          --\n",
       "│    └─BasicBlock: 2-3                   [1, 128, 30, 30]          --\n",
       "│    │    └─Conv2d: 3-13                 [1, 128, 30, 30]          73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 128, 30, 30]          256\n",
       "│    │    └─ReLU: 3-15                   [1, 128, 30, 30]          --\n",
       "│    │    └─Conv2d: 3-16                 [1, 128, 30, 30]          147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [1, 128, 30, 30]          256\n",
       "│    │    └─Sequential: 3-18             [1, 128, 30, 30]          8,448\n",
       "│    │    └─ReLU: 3-19                   [1, 128, 30, 30]          --\n",
       "│    └─BasicBlock: 2-4                   [1, 128, 30, 30]          --\n",
       "│    │    └─Conv2d: 3-20                 [1, 128, 30, 30]          147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [1, 128, 30, 30]          256\n",
       "│    │    └─ReLU: 3-22                   [1, 128, 30, 30]          --\n",
       "│    │    └─Conv2d: 3-23                 [1, 128, 30, 30]          147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [1, 128, 30, 30]          256\n",
       "│    │    └─ReLU: 3-25                   [1, 128, 30, 30]          --\n",
       "├─Sequential: 1-7                        [1, 256, 15, 15]          --\n",
       "│    └─BasicBlock: 2-5                   [1, 256, 15, 15]          --\n",
       "│    │    └─Conv2d: 3-26                 [1, 256, 15, 15]          294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [1, 256, 15, 15]          512\n",
       "│    │    └─ReLU: 3-28                   [1, 256, 15, 15]          --\n",
       "│    │    └─Conv2d: 3-29                 [1, 256, 15, 15]          589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 256, 15, 15]          512\n",
       "│    │    └─Sequential: 3-31             [1, 256, 15, 15]          33,280\n",
       "│    │    └─ReLU: 3-32                   [1, 256, 15, 15]          --\n",
       "│    └─BasicBlock: 2-6                   [1, 256, 15, 15]          --\n",
       "│    │    └─Conv2d: 3-33                 [1, 256, 15, 15]          589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [1, 256, 15, 15]          512\n",
       "│    │    └─ReLU: 3-35                   [1, 256, 15, 15]          --\n",
       "│    │    └─Conv2d: 3-36                 [1, 256, 15, 15]          589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [1, 256, 15, 15]          512\n",
       "│    │    └─ReLU: 3-38                   [1, 256, 15, 15]          --\n",
       "├─Sequential: 1-8                        [1, 512, 8, 8]            --\n",
       "│    └─BasicBlock: 2-7                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-39                 [1, 512, 8, 8]            1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-41                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-42                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [1, 512, 8, 8]            1,024\n",
       "│    │    └─Sequential: 3-44             [1, 512, 8, 8]            132,096\n",
       "│    │    └─ReLU: 3-45                   [1, 512, 8, 8]            --\n",
       "│    └─BasicBlock: 2-8                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-46                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-48                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-49                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-51                   [1, 512, 8, 8]            --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 1, 1]            --\n",
       "├─Linear: 1-10                           [1, 1000]                 513,000\n",
       "==========================================================================================\n",
       "Total params: 11,689,512\n",
       "Trainable params: 11,689,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.15\n",
       "==========================================================================================\n",
       "Input size (MB): 0.69\n",
       "Forward/backward pass size (MB): 45.94\n",
       "Params size (MB): 46.76\n",
       "Estimated Total Size (MB): 93.39\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18, densenet121, densenet161\n",
    "from torchinfo import summary\n",
    "from model import YOLOResNet\n",
    "\n",
    "m1 = resnet18()\n",
    "summary(m1, (1,3, 240, 240), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bd8abd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "YOLOResNet                                    [1, 40, 40, 2, 141]       --\n",
       "├─Sequential: 1-1                             [1, 512, 40, 40]          --\n",
       "│    └─Conv2d: 2-1                            [1, 64, 80, 80]           3,136\n",
       "│    └─BatchNorm2d: 2-2                       [1, 64, 80, 80]           128\n",
       "│    └─ReLU: 2-3                              [1, 64, 80, 80]           --\n",
       "│    └─MaxPool2d: 2-4                         [1, 64, 40, 40]           --\n",
       "│    └─Sequential: 2-5                        [1, 64, 40, 40]           --\n",
       "│    │    └─BasicBlock: 3-1                   [1, 64, 40, 40]           73,984\n",
       "│    │    └─BasicBlock: 3-2                   [1, 64, 40, 40]           73,984\n",
       "│    └─Sequential: 2-6                        [1, 128, 40, 40]          --\n",
       "│    │    └─BasicBlock: 3-3                   [1, 128, 40, 40]          230,144\n",
       "│    │    └─BasicBlock: 3-4                   [1, 128, 40, 40]          295,424\n",
       "│    └─Sequential: 2-7                        [1, 256, 40, 40]          --\n",
       "│    │    └─BasicBlock: 3-5                   [1, 256, 40, 40]          919,040\n",
       "│    │    └─BasicBlock: 3-6                   [1, 256, 40, 40]          1,180,672\n",
       "│    └─Sequential: 2-8                        [1, 512, 40, 40]          --\n",
       "│    │    └─BasicBlock: 3-7                   [1, 512, 40, 40]          3,673,088\n",
       "│    │    └─BasicBlock: 3-8                   [1, 512, 40, 40]          4,720,640\n",
       "├─Conv2d: 1-2                                 [1, 282, 40, 40]          144,666\n",
       "===============================================================================================\n",
       "Total params: 11,314,906\n",
       "Trainable params: 11,314,906\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 18.10\n",
       "===============================================================================================\n",
       "Input size (MB): 0.23\n",
       "Forward/backward pass size (MB): 131.40\n",
       "Params size (MB): 45.26\n",
       "Estimated Total Size (MB): 176.89\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = YOLOResNet()\n",
    "summary(m3, (1,1, 240, 240), device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9845ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DenseNet                                 [1, 1000]                 --\n",
       "├─Sequential: 1-1                        [1, 1024, 7, 7]           --\n",
       "│    └─Conv2d: 2-1                       [1, 64, 120, 120]         9,408\n",
       "│    └─BatchNorm2d: 2-2                  [1, 64, 120, 120]         128\n",
       "│    └─ReLU: 2-3                         [1, 64, 120, 120]         --\n",
       "│    └─MaxPool2d: 2-4                    [1, 64, 60, 60]           --\n",
       "│    └─_DenseBlock: 2-5                  [1, 256, 60, 60]          --\n",
       "│    │    └─_DenseLayer: 3-1             [1, 32, 60, 60]           45,440\n",
       "│    │    └─_DenseLayer: 3-2             [1, 32, 60, 60]           49,600\n",
       "│    │    └─_DenseLayer: 3-3             [1, 32, 60, 60]           53,760\n",
       "│    │    └─_DenseLayer: 3-4             [1, 32, 60, 60]           57,920\n",
       "│    │    └─_DenseLayer: 3-5             [1, 32, 60, 60]           62,080\n",
       "│    │    └─_DenseLayer: 3-6             [1, 32, 60, 60]           66,240\n",
       "│    └─_Transition: 2-6                  [1, 128, 30, 30]          --\n",
       "│    │    └─BatchNorm2d: 3-7             [1, 256, 60, 60]          512\n",
       "│    │    └─ReLU: 3-8                    [1, 256, 60, 60]          --\n",
       "│    │    └─Conv2d: 3-9                  [1, 128, 60, 60]          32,768\n",
       "│    │    └─AvgPool2d: 3-10              [1, 128, 30, 30]          --\n",
       "│    └─_DenseBlock: 2-7                  [1, 512, 30, 30]          --\n",
       "│    │    └─_DenseLayer: 3-11            [1, 32, 30, 30]           53,760\n",
       "│    │    └─_DenseLayer: 3-12            [1, 32, 30, 30]           57,920\n",
       "│    │    └─_DenseLayer: 3-13            [1, 32, 30, 30]           62,080\n",
       "│    │    └─_DenseLayer: 3-14            [1, 32, 30, 30]           66,240\n",
       "│    │    └─_DenseLayer: 3-15            [1, 32, 30, 30]           70,400\n",
       "│    │    └─_DenseLayer: 3-16            [1, 32, 30, 30]           74,560\n",
       "│    │    └─_DenseLayer: 3-17            [1, 32, 30, 30]           78,720\n",
       "│    │    └─_DenseLayer: 3-18            [1, 32, 30, 30]           82,880\n",
       "│    │    └─_DenseLayer: 3-19            [1, 32, 30, 30]           87,040\n",
       "│    │    └─_DenseLayer: 3-20            [1, 32, 30, 30]           91,200\n",
       "│    │    └─_DenseLayer: 3-21            [1, 32, 30, 30]           95,360\n",
       "│    │    └─_DenseLayer: 3-22            [1, 32, 30, 30]           99,520\n",
       "│    └─_Transition: 2-8                  [1, 256, 15, 15]          --\n",
       "│    │    └─BatchNorm2d: 3-23            [1, 512, 30, 30]          1,024\n",
       "│    │    └─ReLU: 3-24                   [1, 512, 30, 30]          --\n",
       "│    │    └─Conv2d: 3-25                 [1, 256, 30, 30]          131,072\n",
       "│    │    └─AvgPool2d: 3-26              [1, 256, 15, 15]          --\n",
       "│    └─_DenseBlock: 2-9                  [1, 1024, 15, 15]         --\n",
       "│    │    └─_DenseLayer: 3-27            [1, 32, 15, 15]           70,400\n",
       "│    │    └─_DenseLayer: 3-28            [1, 32, 15, 15]           74,560\n",
       "│    │    └─_DenseLayer: 3-29            [1, 32, 15, 15]           78,720\n",
       "│    │    └─_DenseLayer: 3-30            [1, 32, 15, 15]           82,880\n",
       "│    │    └─_DenseLayer: 3-31            [1, 32, 15, 15]           87,040\n",
       "│    │    └─_DenseLayer: 3-32            [1, 32, 15, 15]           91,200\n",
       "│    │    └─_DenseLayer: 3-33            [1, 32, 15, 15]           95,360\n",
       "│    │    └─_DenseLayer: 3-34            [1, 32, 15, 15]           99,520\n",
       "│    │    └─_DenseLayer: 3-35            [1, 32, 15, 15]           103,680\n",
       "│    │    └─_DenseLayer: 3-36            [1, 32, 15, 15]           107,840\n",
       "│    │    └─_DenseLayer: 3-37            [1, 32, 15, 15]           112,000\n",
       "│    │    └─_DenseLayer: 3-38            [1, 32, 15, 15]           116,160\n",
       "│    │    └─_DenseLayer: 3-39            [1, 32, 15, 15]           120,320\n",
       "│    │    └─_DenseLayer: 3-40            [1, 32, 15, 15]           124,480\n",
       "│    │    └─_DenseLayer: 3-41            [1, 32, 15, 15]           128,640\n",
       "│    │    └─_DenseLayer: 3-42            [1, 32, 15, 15]           132,800\n",
       "│    │    └─_DenseLayer: 3-43            [1, 32, 15, 15]           136,960\n",
       "│    │    └─_DenseLayer: 3-44            [1, 32, 15, 15]           141,120\n",
       "│    │    └─_DenseLayer: 3-45            [1, 32, 15, 15]           145,280\n",
       "│    │    └─_DenseLayer: 3-46            [1, 32, 15, 15]           149,440\n",
       "│    │    └─_DenseLayer: 3-47            [1, 32, 15, 15]           153,600\n",
       "│    │    └─_DenseLayer: 3-48            [1, 32, 15, 15]           157,760\n",
       "│    │    └─_DenseLayer: 3-49            [1, 32, 15, 15]           161,920\n",
       "│    │    └─_DenseLayer: 3-50            [1, 32, 15, 15]           166,080\n",
       "│    └─_Transition: 2-10                 [1, 512, 7, 7]            --\n",
       "│    │    └─BatchNorm2d: 3-51            [1, 1024, 15, 15]         2,048\n",
       "│    │    └─ReLU: 3-52                   [1, 1024, 15, 15]         --\n",
       "│    │    └─Conv2d: 3-53                 [1, 512, 15, 15]          524,288\n",
       "│    │    └─AvgPool2d: 3-54              [1, 512, 7, 7]            --\n",
       "│    └─_DenseBlock: 2-11                 [1, 1024, 7, 7]           --\n",
       "│    │    └─_DenseLayer: 3-55            [1, 32, 7, 7]             103,680\n",
       "│    │    └─_DenseLayer: 3-56            [1, 32, 7, 7]             107,840\n",
       "│    │    └─_DenseLayer: 3-57            [1, 32, 7, 7]             112,000\n",
       "│    │    └─_DenseLayer: 3-58            [1, 32, 7, 7]             116,160\n",
       "│    │    └─_DenseLayer: 3-59            [1, 32, 7, 7]             120,320\n",
       "│    │    └─_DenseLayer: 3-60            [1, 32, 7, 7]             124,480\n",
       "│    │    └─_DenseLayer: 3-61            [1, 32, 7, 7]             128,640\n",
       "│    │    └─_DenseLayer: 3-62            [1, 32, 7, 7]             132,800\n",
       "│    │    └─_DenseLayer: 3-63            [1, 32, 7, 7]             136,960\n",
       "│    │    └─_DenseLayer: 3-64            [1, 32, 7, 7]             141,120\n",
       "│    │    └─_DenseLayer: 3-65            [1, 32, 7, 7]             145,280\n",
       "│    │    └─_DenseLayer: 3-66            [1, 32, 7, 7]             149,440\n",
       "│    │    └─_DenseLayer: 3-67            [1, 32, 7, 7]             153,600\n",
       "│    │    └─_DenseLayer: 3-68            [1, 32, 7, 7]             157,760\n",
       "│    │    └─_DenseLayer: 3-69            [1, 32, 7, 7]             161,920\n",
       "│    │    └─_DenseLayer: 3-70            [1, 32, 7, 7]             166,080\n",
       "│    └─BatchNorm2d: 2-12                 [1, 1024, 7, 7]           2,048\n",
       "├─Linear: 1-2                            [1, 1000]                 1,025,000\n",
       "==========================================================================================\n",
       "Total params: 7,978,856\n",
       "Trainable params: 7,978,856\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.24\n",
       "==========================================================================================\n",
       "Input size (MB): 0.69\n",
       "Forward/backward pass size (MB): 206.23\n",
       "Params size (MB): 31.92\n",
       "Estimated Total Size (MB): 238.83\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = densenet121()\n",
    "summary(m2, (1, 3, 240, 240), device=\"cpu\")\n",
    "##seems like densenet has less paraemters (30% less!) -> better convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebd9de4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 896, 896]           2,352\n",
      "       BatchNorm2d-2         [-1, 16, 896, 896]              32\n",
      "         LeakyReLU-3         [-1, 16, 896, 896]               0\n",
      "        _ConvBlock-4         [-1, 16, 896, 896]               0\n",
      "         MaxPool2d-5         [-1, 16, 448, 448]               0\n",
      "            Conv2d-6         [-1, 32, 448, 448]           4,608\n",
      "       BatchNorm2d-7         [-1, 32, 448, 448]              64\n",
      "         LeakyReLU-8         [-1, 32, 448, 448]               0\n",
      "        _ConvBlock-9         [-1, 32, 448, 448]               0\n",
      "        MaxPool2d-10         [-1, 32, 224, 224]               0\n",
      "           Conv2d-11         [-1, 48, 224, 224]           1,536\n",
      "      BatchNorm2d-12         [-1, 48, 224, 224]              96\n",
      "        LeakyReLU-13         [-1, 48, 224, 224]               0\n",
      "       _ConvBlock-14         [-1, 48, 224, 224]               0\n",
      "           Conv2d-15         [-1, 64, 224, 224]          27,648\n",
      "      BatchNorm2d-16         [-1, 64, 224, 224]             128\n",
      "        LeakyReLU-17         [-1, 64, 224, 224]               0\n",
      "       _ConvBlock-18         [-1, 64, 224, 224]               0\n",
      "           Conv2d-19        [-1, 128, 224, 224]           8,192\n",
      "      BatchNorm2d-20        [-1, 128, 224, 224]             256\n",
      "        LeakyReLU-21        [-1, 128, 224, 224]               0\n",
      "       _ConvBlock-22        [-1, 128, 224, 224]               0\n",
      "        MaxPool2d-23        [-1, 128, 112, 112]               0\n",
      "           Conv2d-24        [-1, 256, 112, 112]         294,912\n",
      "      BatchNorm2d-25        [-1, 256, 112, 112]             512\n",
      "        LeakyReLU-26        [-1, 256, 112, 112]               0\n",
      "       _ConvBlock-27        [-1, 256, 112, 112]               0\n",
      "           Conv2d-28        [-1, 512, 112, 112]       1,179,648\n",
      "      BatchNorm2d-29        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-30        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-31        [-1, 512, 112, 112]               0\n",
      "           Conv2d-32        [-1, 256, 112, 112]         131,072\n",
      "      BatchNorm2d-33        [-1, 256, 112, 112]             512\n",
      "        LeakyReLU-34        [-1, 256, 112, 112]               0\n",
      "       _ConvBlock-35        [-1, 256, 112, 112]               0\n",
      "           Conv2d-36        [-1, 512, 112, 112]       1,179,648\n",
      "      BatchNorm2d-37        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-38        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-39        [-1, 512, 112, 112]               0\n",
      "           Conv2d-40        [-1, 256, 112, 112]         131,072\n",
      "      BatchNorm2d-41        [-1, 256, 112, 112]             512\n",
      "        LeakyReLU-42        [-1, 256, 112, 112]               0\n",
      "       _ConvBlock-43        [-1, 256, 112, 112]               0\n",
      "           Conv2d-44        [-1, 512, 112, 112]       1,179,648\n",
      "      BatchNorm2d-45        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-46        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-47        [-1, 512, 112, 112]               0\n",
      "           Conv2d-48        [-1, 256, 112, 112]         131,072\n",
      "      BatchNorm2d-49        [-1, 256, 112, 112]             512\n",
      "        LeakyReLU-50        [-1, 256, 112, 112]               0\n",
      "       _ConvBlock-51        [-1, 256, 112, 112]               0\n",
      "           Conv2d-52        [-1, 512, 112, 112]       1,179,648\n",
      "      BatchNorm2d-53        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-54        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-55        [-1, 512, 112, 112]               0\n",
      "           Conv2d-56        [-1, 256, 112, 112]         131,072\n",
      "      BatchNorm2d-57        [-1, 256, 112, 112]             512\n",
      "        LeakyReLU-58        [-1, 256, 112, 112]               0\n",
      "       _ConvBlock-59        [-1, 256, 112, 112]               0\n",
      "           Conv2d-60        [-1, 512, 112, 112]       1,179,648\n",
      "      BatchNorm2d-61        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-62        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-63        [-1, 512, 112, 112]               0\n",
      "           Conv2d-64        [-1, 512, 112, 112]         262,144\n",
      "      BatchNorm2d-65        [-1, 512, 112, 112]           1,024\n",
      "        LeakyReLU-66        [-1, 512, 112, 112]               0\n",
      "       _ConvBlock-67        [-1, 512, 112, 112]               0\n",
      "           Conv2d-68       [-1, 1024, 112, 112]       4,718,592\n",
      "      BatchNorm2d-69       [-1, 1024, 112, 112]           2,048\n",
      "        LeakyReLU-70       [-1, 1024, 112, 112]               0\n",
      "       _ConvBlock-71       [-1, 1024, 112, 112]               0\n",
      "           Conv2d-72       [-1, 1024, 112, 112]       9,437,184\n",
      "      BatchNorm2d-73       [-1, 1024, 112, 112]           2,048\n",
      "        LeakyReLU-74       [-1, 1024, 112, 112]               0\n",
      "       _ConvBlock-75       [-1, 1024, 112, 112]               0\n",
      "           Conv2d-76        [-1, 846, 112, 112]         866,304\n",
      "      BatchNorm2d-77        [-1, 846, 112, 112]           1,692\n",
      "        LeakyReLU-78        [-1, 846, 112, 112]               0\n",
      "       _ConvBlock-79        [-1, 846, 112, 112]               0\n",
      "================================================================\n",
      "Total params: 22,061,068\n",
      "Trainable params: 22,061,068\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 9.19\n",
      "Forward/backward pass size (MB): 3778.36\n",
      "Params size (MB): 84.16\n",
      "Estimated Total Size (MB): 3871.70\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import model as m\n",
    "\n",
    "model = m.YOLOv2Heavy().cpu()    # move to CPU\n",
    "summary(model, (3, 896, 896), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd4f3ebe-7b56-4306-bfe3-b872c60e82ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint_idx</th>\n",
       "      <th>n_crops</th>\n",
       "      <th>epoch</th>\n",
       "      <th>mAP</th>\n",
       "      <th>c_lr</th>\n",
       "      <th>c_xy</th>\n",
       "      <th>c_wh</th>\n",
       "      <th>c_obj</th>\n",
       "      <th>c_noobj</th>\n",
       "      <th>c_cls</th>\n",
       "      <th>l_total</th>\n",
       "      <th>l_xy</th>\n",
       "      <th>l_wh</th>\n",
       "      <th>l_obj</th>\n",
       "      <th>l_noobj</th>\n",
       "      <th>l_cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>696</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>275.344138</td>\n",
       "      <td>5.499860</td>\n",
       "      <td>135.400364</td>\n",
       "      <td>11.637647</td>\n",
       "      <td>12.164513</td>\n",
       "      <td>110.641758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>192.068705</td>\n",
       "      <td>3.855599</td>\n",
       "      <td>97.991488</td>\n",
       "      <td>3.729274</td>\n",
       "      <td>8.400395</td>\n",
       "      <td>78.091948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>167.269900</td>\n",
       "      <td>3.283643</td>\n",
       "      <td>87.710228</td>\n",
       "      <td>3.162343</td>\n",
       "      <td>6.575721</td>\n",
       "      <td>66.537964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5744</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012411</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.944026</td>\n",
       "      <td>2.931033</td>\n",
       "      <td>70.878944</td>\n",
       "      <td>2.739598</td>\n",
       "      <td>5.562097</td>\n",
       "      <td>55.832354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>11504</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.751530</td>\n",
       "      <td>2.655073</td>\n",
       "      <td>58.119696</td>\n",
       "      <td>2.172466</td>\n",
       "      <td>4.462927</td>\n",
       "      <td>45.341369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>11504</td>\n",
       "      <td>2</td>\n",
       "      <td>0.026857</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.841610</td>\n",
       "      <td>2.446533</td>\n",
       "      <td>45.778183</td>\n",
       "      <td>1.803749</td>\n",
       "      <td>3.692962</td>\n",
       "      <td>36.120183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>11504</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021348</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.103799</td>\n",
       "      <td>2.307255</td>\n",
       "      <td>35.322209</td>\n",
       "      <td>1.504401</td>\n",
       "      <td>3.182007</td>\n",
       "      <td>28.787926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>11504</td>\n",
       "      <td>4</td>\n",
       "      <td>0.044709</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.577379</td>\n",
       "      <td>2.206758</td>\n",
       "      <td>26.867742</td>\n",
       "      <td>1.377693</td>\n",
       "      <td>2.826493</td>\n",
       "      <td>22.298693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>11504</td>\n",
       "      <td>5</td>\n",
       "      <td>0.037146</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.496527</td>\n",
       "      <td>2.123826</td>\n",
       "      <td>20.919877</td>\n",
       "      <td>1.180165</td>\n",
       "      <td>2.490733</td>\n",
       "      <td>16.781926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ModelSeries as ms\n",
    "import config as c\n",
    "from IPython import display\n",
    "from importlib import reload\n",
    "from IPython.display import display, HTML\n",
    "import util\n",
    "\n",
    "reload(util)\n",
    "reload(ms)\n",
    "reload(c)\n",
    "\n",
    "series = ms.ModelSeries(name = \"debug_modelseries_training\", mode = \"profiling\")\n",
    "\n",
    "display(HTML(series.records.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8af09dfa-7f5e-4787-97f5-ad2e22eeb0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelSeries: loadJsonData()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint_idx</th>\n",
       "      <th>n_crops</th>\n",
       "      <th>epoch</th>\n",
       "      <th>mAP</th>\n",
       "      <th>c_lr</th>\n",
       "      <th>c_xy</th>\n",
       "      <th>c_wh</th>\n",
       "      <th>c_obj</th>\n",
       "      <th>c_noobj</th>\n",
       "      <th>c_cls</th>\n",
       "      <th>l_total</th>\n",
       "      <th>l_xy</th>\n",
       "      <th>l_wh</th>\n",
       "      <th>l_obj</th>\n",
       "      <th>l_noobj</th>\n",
       "      <th>l_cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1188.276653</td>\n",
       "      <td>8.048184</td>\n",
       "      <td>968.950649</td>\n",
       "      <td>13.092112</td>\n",
       "      <td>82.671938</td>\n",
       "      <td>115.513760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023161</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.261784</td>\n",
       "      <td>2.927711</td>\n",
       "      <td>72.829138</td>\n",
       "      <td>2.877847</td>\n",
       "      <td>6.085329</td>\n",
       "      <td>54.541759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.068692</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.515978</td>\n",
       "      <td>2.072663</td>\n",
       "      <td>49.288987</td>\n",
       "      <td>1.584036</td>\n",
       "      <td>2.969086</td>\n",
       "      <td>30.601206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.051288</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.408172</td>\n",
       "      <td>1.882155</td>\n",
       "      <td>42.838701</td>\n",
       "      <td>1.231322</td>\n",
       "      <td>2.314950</td>\n",
       "      <td>23.141044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.106579</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.099367</td>\n",
       "      <td>1.787627</td>\n",
       "      <td>37.648063</td>\n",
       "      <td>1.004053</td>\n",
       "      <td>1.986637</td>\n",
       "      <td>18.672987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.134821</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.545663</td>\n",
       "      <td>1.714541</td>\n",
       "      <td>32.093379</td>\n",
       "      <td>0.943265</td>\n",
       "      <td>1.775987</td>\n",
       "      <td>15.018490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.159319</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.732913</td>\n",
       "      <td>1.651732</td>\n",
       "      <td>26.042073</td>\n",
       "      <td>0.844717</td>\n",
       "      <td>1.567830</td>\n",
       "      <td>11.626562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.136163</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.284919</td>\n",
       "      <td>1.584544</td>\n",
       "      <td>20.838452</td>\n",
       "      <td>0.748832</td>\n",
       "      <td>1.433210</td>\n",
       "      <td>8.679881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>7</td>\n",
       "      <td>0.160402</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.275116</td>\n",
       "      <td>1.522819</td>\n",
       "      <td>16.534314</td>\n",
       "      <td>0.686169</td>\n",
       "      <td>1.298192</td>\n",
       "      <td>6.233623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152414</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.827030</td>\n",
       "      <td>1.467150</td>\n",
       "      <td>13.739863</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>1.199784</td>\n",
       "      <td>4.760427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>9</td>\n",
       "      <td>0.182355</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.609454</td>\n",
       "      <td>1.417721</td>\n",
       "      <td>11.657406</td>\n",
       "      <td>0.597767</td>\n",
       "      <td>1.108684</td>\n",
       "      <td>3.827876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>9</td>\n",
       "      <td>0.186091</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.595223</td>\n",
       "      <td>1.412618</td>\n",
       "      <td>11.458796</td>\n",
       "      <td>0.691241</td>\n",
       "      <td>1.100137</td>\n",
       "      <td>3.932430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.193218</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.679171</td>\n",
       "      <td>1.341987</td>\n",
       "      <td>9.796211</td>\n",
       "      <td>0.613367</td>\n",
       "      <td>0.999085</td>\n",
       "      <td>2.928521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>11</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.337219</td>\n",
       "      <td>1.297553</td>\n",
       "      <td>8.949729</td>\n",
       "      <td>0.661738</td>\n",
       "      <td>0.939666</td>\n",
       "      <td>2.488533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>9200</td>\n",
       "      <td>12</td>\n",
       "      <td>0.229552</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.102085</td>\n",
       "      <td>1.256250</td>\n",
       "      <td>8.090245</td>\n",
       "      <td>0.689973</td>\n",
       "      <td>0.872931</td>\n",
       "      <td>2.192687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ModelSeries as ms\n",
    "import config as c\n",
    "from IPython import display\n",
    "from importlib import reload\n",
    "from IPython.display import display, HTML\n",
    "import util\n",
    "\n",
    "reload(util)\n",
    "reload(ms)\n",
    "reload(c)\n",
    "\n",
    "series = ms.ModelSeries(name = \"train_with_lr1e-2\", mode = \"\")\n",
    "\n",
    "display(HTML(series.records.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1025e3de-37f5-4144-be92-5eac7d28f4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelSeries: loadJsonData()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint_idx</th>\n",
       "      <th>n_crops</th>\n",
       "      <th>epoch</th>\n",
       "      <th>mAP</th>\n",
       "      <th>c_lr</th>\n",
       "      <th>c_xy</th>\n",
       "      <th>c_wh</th>\n",
       "      <th>c_obj</th>\n",
       "      <th>c_noobj</th>\n",
       "      <th>c_cls</th>\n",
       "      <th>l_total</th>\n",
       "      <th>l_xy</th>\n",
       "      <th>l_wh</th>\n",
       "      <th>l_obj</th>\n",
       "      <th>l_noobj</th>\n",
       "      <th>l_cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>11504</td>\n",
       "      <td>4</td>\n",
       "      <td>0.067031</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.951487</td>\n",
       "      <td>1.741456</td>\n",
       "      <td>28.525161</td>\n",
       "      <td>1.065523</td>\n",
       "      <td>1.922221</td>\n",
       "      <td>14.697127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>11504</td>\n",
       "      <td>5</td>\n",
       "      <td>0.069234</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.328332</td>\n",
       "      <td>1.665602</td>\n",
       "      <td>22.547944</td>\n",
       "      <td>0.886763</td>\n",
       "      <td>1.696149</td>\n",
       "      <td>10.531874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2880</td>\n",
       "      <td>5</td>\n",
       "      <td>0.031588</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.246364</td>\n",
       "      <td>2.054568</td>\n",
       "      <td>48.889957</td>\n",
       "      <td>2.066470</td>\n",
       "      <td>4.297125</td>\n",
       "      <td>28.938245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2880</td>\n",
       "      <td>5</td>\n",
       "      <td>0.074603</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.073360</td>\n",
       "      <td>1.754313</td>\n",
       "      <td>31.456503</td>\n",
       "      <td>1.345778</td>\n",
       "      <td>2.234983</td>\n",
       "      <td>16.281783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>5744</td>\n",
       "      <td>5</td>\n",
       "      <td>0.091949</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.792591</td>\n",
       "      <td>1.662509</td>\n",
       "      <td>25.524948</td>\n",
       "      <td>1.012105</td>\n",
       "      <td>1.795628</td>\n",
       "      <td>11.797402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series = ms.ModelSeries(name = \"train_with_lr1e-3\", mode = \"profiling\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
